train:
  batch_size : 8
  num_workers : 8
  learning_rate : 0.0003
  decay_step : 5
  decay_gamma : 0.1
  num_epochs : 15
  save_seq : 1
  loss_lambda : 30.0
  input_size : [512, 512]