train:
  batch_size : 4
  num_workers : 8
  learning_rate : 0.0005
  decay_step : 10
  decay_gamma : 0.1
  num_epochs : 30
  save_seq : 1
  loss_lambda : 2.0
  input_size : [512, 512]